{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual information\n",
    "\n",
    "The mutual information measures the reduction in uncertainty in variable A when variable B is known. \n",
    "\n",
    "To select variables, we are interested in the mutual information between the predictor variables and the target. Higher mutual information values, indicate little uncertainty about the target Y given the predictor X.\n",
    "\n",
    "[Mutual Information, Wikipedia](https://en.wikipedia.org/wiki/Mutual_information):\n",
    "\n",
    "Using Scikit-learn, we can determine the mutual information between a variable and the target using the mutual_info_classif or mutual_info_regression for binary or continuous targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to obtain the mutual information values\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "# to select the features\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "data = pd.read_csv('../Data/dataset_2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mutual information between the variables and the target\n",
    "\n",
    "# the smaller the value of the mi, the less information we can infer from\n",
    "# the feature about the target\n",
    "\n",
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1) let's capture the above array in a pandas series\n",
    "# 2)add the variable names in the index\n",
    "# 3) sort the features based on their mutual information value\n",
    "# 4) and make a var plot\n",
    "\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False).plot.bar(figsize=(20, 6))\n",
    "plt.ylabel('Mutual Information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few features (left of the plot) with higher mutual information values. There are also features with almost zero MI values on the right of the plot.\n",
    "\n",
    "Once we find the mutual information values, to select features we need to determine a threshold, or cut-off value, above which a feature will be selected.\n",
    "\n",
    "There are a few ways in which this can be done:\n",
    "\n",
    "- Select top k features, where k is an arbitrary number of features\n",
    "\n",
    "- Select features in the top n percentile, where n is again an arbitrary number\n",
    "\n",
    "- Select all features above a certain threshold of MI, arbitrarily decided.\n",
    "\n",
    "Scikit-learn transformer **SelectKBest**, allows us to automatically select the top k features, based of any statistical value, including the MI.\n",
    "\n",
    "Sklearn's **SelectPercentile** allows us to select the features in the top percentile of any statistical value, including the MI.\n",
    "\n",
    "Alternatively, if we want to select features based on a MI threshold, we can do it manually.\n",
    "\n",
    "### Select top k features based on MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will select the top 10 features\n",
    "# based on their mutual information value\n",
    "\n",
    "# select features\n",
    "sel_ = SelectKBest(mutual_info_classif, k=10).fit(X_train, y_train)\n",
    "\n",
    "# display features\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the rest of the features:\n",
    "\n",
    "X_train = sel_.transform(X_train)\n",
    "X_test = sel_.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('../houseprice.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill missing values\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# determine the mutual information\n",
    "mi = mutual_info_regression(X_train, y_train)\n",
    "\n",
    "# and make a bar  plot\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False).plot.bar(figsize=(20,6))\n",
    "plt.ylabel('Mutual Information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top 10th percentile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features in the top percentile\n",
    "sel_ = SelectPercentile(mutual_info_regression, percentile=10).fit(X_train, y_train)\n",
    "\n",
    "# display the features\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the rest of the features:\n",
    "\n",
    "X_train = sel_.transform(X_train)\n",
    "X_test = sel_.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not personally used mutual information in any of my projects. However, there is some value in the method. See for example:\n",
    "\n",
    "Comparison between univariate and mutual information selection in [sklean website](http://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py)\n",
    "\n",
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
